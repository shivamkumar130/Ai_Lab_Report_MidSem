{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpL6ZSSK5YgoTRUFi6qSHx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/El-47/CS367_Lab_Midsem_Report/blob/master/Week3/Week3a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qbK66-0Q8Zz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Node**\n",
        "The `GraphNode` class creates a node for representing a state in a graph. It has the following attributes:\n",
        "\n",
        "- **Parent Node:** Refers to the node that led to the current node.\n",
        "- **State:** The state or value the node holds.\n",
        "- **Cost:** The cumulative cost associated with reaching this node.\n",
        "\n",
        "The class makes use of these built-in methods:\n",
        "\n",
        "- **`__hash__`:** Generates a unique hash value for the node, making it suitable for use in sets or as dictionary keys.\n",
        "- **`__eq__`:** Checks if two nodes are equal, based on their states (overloaded equality operator).\n",
        "- **`__ne__`:** Determines if two nodes are not equal (overloaded inequality operator).\n",
        "- **`__str__`:** Provides a string representation of the node's state."
      ],
      "metadata": {
        "id": "4x_HzhIaS6eO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    def __init__(self, parent, state, pcost, hcost, action=None):\n",
        "\n",
        "        self.parent = parent\n",
        "        self.state = state\n",
        "        self.action = action\n",
        "        self.pcost = pcost\n",
        "        self.hcost = hcost\n",
        "        self.cost = pcost + hcost\n",
        "\n",
        "    def __hash__(self):\n",
        "\n",
        "        return hash(str(self.state.flatten()))\n",
        "\n",
        "    def __str__(self):\n",
        "        return str(self.state)\n",
        "\n",
        "    def __eq__(self, other):\n",
        "\n",
        "        return hash(''.join(self.state.flatten())) == hash(''.join(other.state.flatten()))\n",
        "\n",
        "    def __ne__(self, other):\n",
        "        return hash(''.join(self.state.flatten())) != hash(''.join(other.state.flatten()))"
      ],
      "metadata": {
        "id": "U6bC2VimT4eL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Priority Queue Class\n",
        "\n",
        "The **Priority Queue** class is used to store graph nodes along with their costs. It ensures that the node with the lowest cost is popped first, which is essential for algorithms like BFS.\n",
        "\n",
        "#### Methods:\n",
        "- **`push`:** Adds a node to the queue while maintaining order based on cost.\n",
        "- **`pop`:** Removes and returns the node with the lowest cost.\n",
        "- **`is_empty`:** Checks if the queue is empty.\n",
        "- **`__len__`:** Returns the length of the queue.\n",
        "- **`__str__`:** Provides a string representation of the current state of the queue."
      ],
      "metadata": {
        "id": "vqISaay-WkEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PriorityQueue():\n",
        "\n",
        "    def __init__(self):\n",
        "        self.queue = []\n",
        "        self.hashes = {}\n",
        "\n",
        "    def push(self, node):\n",
        "        if hash(node) not in self.hashes:\n",
        "            self.hashes[hash(node)] = 1\n",
        "            self.queue.append(node)\n",
        "\n",
        "    def pop(self):\n",
        "\n",
        "        next_state = None\n",
        "        state_cost = 10**18\n",
        "        index = -1\n",
        "\n",
        "        for i in range(len(self.queue)):\n",
        "\n",
        "            if self.queue[i].cost<state_cost:\n",
        "                state_cost = self.queue[i].cost\n",
        "                index = i\n",
        "\n",
        "        return self.queue.pop(index)\n",
        "\n",
        "    def is_empty(self):\n",
        "\n",
        "        return len(self.queue)==0\n",
        "\n",
        "    def __str__(self):\n",
        "        l = []\n",
        "        for i in self.queue:\n",
        "            l.append(i.state)\n",
        "\n",
        "        return str(l)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.queue)"
      ],
      "metadata": {
        "id": "5UgYK_SWWmor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Environment Class\n",
        "\n",
        "The **Environment** class models the world in which the agent operates. It defines the actions available to the agent, the start and goal states, and the depth of the solution.\n",
        "\n",
        "#### Entities:\n",
        "- **`actions`:** A list of possible actions in the environment.\n",
        "- **`depth`:** Maximum number of moves allowed to find the solution.\n",
        "- **`goal_state`:** The desired goal state.\n",
        "- **`start_state`:** The initial state generated from a series of moves starting from the goal state.\n",
        "\n",
        "#### Functions:\n",
        "- **`get_start_state`:** Returns the start state of the environment.\n",
        "- **`reached_goal`:** Checks if the current state matches the goal state.\n",
        "- **`get_next_states`:** Takes the current state and returns a list of all possible subsequent states.\n",
        "- **`generate_start_state`:** Generates the start state by making `d` moves from the goal state."
      ],
      "metadata": {
        "id": "pfiggKSyYirn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Environment():\n",
        "\n",
        "    def __init__(self, start_state=None, goal_state=None):\n",
        "        self.actions = [1,2,3,4] #1 - Up, 2 - Down, 3 - Right, 4 - Left\n",
        "        if goal_state is None:\n",
        "            self.goal_state = self.generate_goal_state()\n",
        "        else:\n",
        "            self.goal_state = goal_state\n",
        "        if start_state is None:\n",
        "            self.start_state = self.generate_start_state()\n",
        "        else:\n",
        "            self.start_state = start_state\n",
        "\n",
        "    def generate_start_state(self):\n",
        "\n",
        "        start = np.zeros((7,7))\n",
        "        x = (0,1,5,6)\n",
        "        y = (0,1,5,6)\n",
        "\n",
        "        for i in x:\n",
        "            for j in y:\n",
        "                start[i][j] = -1;\n",
        "\n",
        "        x = (2,3,4)\n",
        "        y = range(7)\n",
        "\n",
        "        for i in x:\n",
        "            for j in y:\n",
        "                start[i][j] = 1\n",
        "                start[j][i] = 1\n",
        "        start[3][3] = 0\n",
        "\n",
        "        return start\n",
        "\n",
        "    def generate_goal_state(self):\n",
        "\n",
        "        goal = np.zeros((7,7))\n",
        "        x = (0,1,5,6)\n",
        "        y = (0,1,5,6)\n",
        "\n",
        "        for i in x:\n",
        "            for j in y:\n",
        "                goal[i][j] = -1;\n",
        "\n",
        "        x = (2,3,4)\n",
        "        y = range(7)\n",
        "\n",
        "        for i in x:\n",
        "            for j in y:\n",
        "                goal[i][j] = 0\n",
        "                goal[j][i] = 0\n",
        "        goal[3][3] = 1\n",
        "        return goal\n",
        "\n",
        "    def get_start_state(self):\n",
        "        return self.start_state\n",
        "\n",
        "    def get_goal_state(self):\n",
        "        return self.goal_state\n",
        "\n",
        "    def get_next_states(self, state):\n",
        "\n",
        "        new_states = []\n",
        "        spaces = []\n",
        "        for i in range(7):\n",
        "            for j in range(7):\n",
        "                if state[i][j]==0:\n",
        "                    spaces.append((i,j))\n",
        "\n",
        "        for space in spaces:\n",
        "\n",
        "            x, y = space\n",
        "            #Move from top to bottom\n",
        "            if x>1:\n",
        "                if state[x-1][y]==1 and state[x-2][y]==1:\n",
        "                    new_state = state.copy()\n",
        "                    new_state[x][y] = 1\n",
        "                    new_state[x-2][y] = 0\n",
        "                    new_state[x-1][y] = 0\n",
        "                    action = f'({x-2}, {y}) -> ({x}, {y})'\n",
        "                    new_states.append((new_state, action))\n",
        "            #Move from bottom to top\n",
        "            if x<5:\n",
        "                if state[x+1][y]==1 and state[x+2][y]==1:\n",
        "                    new_state = state.copy()\n",
        "                    new_state[x][y] = 1\n",
        "                    new_state[x+2][y] = 0\n",
        "                    new_state[x+1][y] = 0\n",
        "                    action = f'({x+2}, {y}) -> ({x}, {y})'\n",
        "                    new_states.append((new_state, action))\n",
        "\n",
        "            #Move from left to right\n",
        "            if y>1:\n",
        "                if state[x][y-1]==1 and state[x][y-2]==1:\n",
        "                    new_state = state.copy()\n",
        "                    new_state[x][y] = 1\n",
        "                    new_state[x][y-2] = 0\n",
        "                    new_state[x][y-1] = 0\n",
        "                    action = f'({x}, {y-2}) -> ({x}, {y})'\n",
        "                    new_states.append((new_state, action))\n",
        "\n",
        "            if y<5:\n",
        "                if state[x][y+1]==1 and state[x][y+2]==1:\n",
        "                    new_state = state.copy()\n",
        "                    new_state[x][y] = 1\n",
        "                    new_state[x][y+2] = 0\n",
        "                    new_state[x][y+1] = 0\n",
        "                    action = f'({x}, {y+2}) -> ({x}, {y})'\n",
        "                    new_states.append((new_state, action))\n",
        "\n",
        "        return new_states\n",
        "\n",
        "    def reached_goal(self, state):\n",
        "\n",
        "        for i in range(7):\n",
        "            for j in range(7):\n",
        "                if state[i,j] != self.goal_state[i,j]:\n",
        "                    return False\n",
        "\n",
        "\n",
        "        return True"
      ],
      "metadata": {
        "id": "l0iwKZ63YlNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Heuristic 0"
      ],
      "metadata": {
        "id": "aJ8kGUNfZB0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def heuristic0(curr_state):\n",
        "    return 0"
      ],
      "metadata": {
        "id": "oCSav9NkZKnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Heuristic 1\n",
        "The **Manhattan Distance** function computes the sum of horizontal and vertical distances between objects in a given state and a reference point, usually the center. This heuristic gives an estimate of how far each object needs to move to reach the target position.\n"
      ],
      "metadata": {
        "id": "gxWKPR8uZNx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def heuristic1(curr_state):\n",
        "    cost = 0\n",
        "    for i in range(7):\n",
        "        for j in range(7):\n",
        "            if curr_state[i][j]==1:\n",
        "                cost += abs(i-3)+abs(j-3)\n",
        "\n",
        "    return cost"
      ],
      "metadata": {
        "id": "4-ugPQEiZXnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Heuristic 2**\n",
        "\n",
        "This is the exponential distance, it returns the 2<sup>max(H,V) </sup>, where H is the horizontal distance, and V is the vertical distance.\n"
      ],
      "metadata": {
        "id": "DKtk36FSbub3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def heuristic2(curr_state):\n",
        "    cost = 0\n",
        "    for i in range(7):\n",
        "        for j in range(7):\n",
        "            if curr_state[i][j]==1:\n",
        "                cost += 2**(max(abs(i-3),abs(j-3)))\n",
        "\n",
        "    return cost"
      ],
      "metadata": {
        "id": "3BNfnKghb4GK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agent Class\n",
        "\n",
        "The **Agent** class represents the player that navigates through the environment with the objective of reaching a goal state. It holds crucial attributes and functions to facilitate this exploration.\n",
        "\n",
        "#### Attributes:\n",
        "- **`frontier`:** A priority queue for storing nodes that are yet to be explored.\n",
        "- **`explored`:** A dictionary to keep track of nodes that have already been explored.\n",
        "- **`start_state`:** The initial state from which the agent starts its journey.\n",
        "- **`goal_state`:** The target state that the agent aims to reach.\n",
        "- **`env`:** An instance representing the environment in which the agent operates.\n",
        "- **`goal_node`:** A reference to the node representing the goal state, if located.\n",
        "- **`heuristic`:** The heuristic function used for calculating path costs.\n",
        "\n",
        "#### Methods:\n",
        "- **`run()`:** This method explores the environment to locate the goal node, employing the heuristic function to determine path costs.\n",
        "- **`print_nodes()`:** Displays the path from the starting node to the goal node."
      ],
      "metadata": {
        "id": "A4w1nU-Nb8DX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent1:\n",
        "\n",
        "    def __init__(self, env, heuristic):\n",
        "        self.frontier = PriorityQueue()\n",
        "        self.explored = dict()\n",
        "        self.start_state = env.get_start_state()\n",
        "        self.goal_state = env.get_goal_state()\n",
        "        self.env = env\n",
        "        self.goal_node = None\n",
        "        self.heuristic = heuristic\n",
        "\n",
        "    def run(self):\n",
        "        init_node = Node(parent = None, state = self.start_state, pcost = 0, hcost = 0)\n",
        "        self.frontier.push(init_node)\n",
        "        start = time()\n",
        "        while not self.frontier.is_empty():\n",
        "\n",
        "            curr_node = self.frontier.pop()\n",
        "            next_states = self.env.get_next_states(curr_node.state)\n",
        "\n",
        "            if hash(curr_node) in self.explored:\n",
        "                continue\n",
        "\n",
        "            self.explored[hash(curr_node)] = curr_node\n",
        "\n",
        "            if self.env.reached_goal(curr_node.state):\n",
        "                print(\"Reached goal!\")\n",
        "                self.goal_node = curr_node\n",
        "                break\n",
        "            goal_state = self.env.get_goal_state()\n",
        "\n",
        "            l = []\n",
        "            for state in next_states:\n",
        "\n",
        "                hcost = self.heuristic(state[0])\n",
        "                node = Node(parent=curr_node, state=state[0], pcost=curr_node.pcost+1, hcost=hcost, action=state[1])\n",
        "                self.frontier.push(node)\n",
        "\n",
        "        end = time()\n",
        "        print(end - start)\n",
        "        return end-start\n",
        "\n",
        "    def print_nodes(self):\n",
        "\n",
        "        node = self.goal_node\n",
        "        l = []\n",
        "        while node is not None:\n",
        "            l.append(node)\n",
        "            node = node.parent\n",
        "\n",
        "        step = 1\n",
        "        for node in l[::-1]:\n",
        "            print(\"Step: \",step)\n",
        "            print(node.action)\n",
        "            step+=1\n",
        "\n"
      ],
      "metadata": {
        "id": "ptD2RCBU73KO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **A-star Search**\n",
        "\n",
        "Using both heuristic cost and path cost\n",
        "\n"
      ],
      "metadata": {
        "id": "HPi_ClcHcN5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = 0\n",
        "for i in range(5):\n",
        "    agent = Agent1(Environment(), heuristic2)\n",
        "    t+=agent.run()\n",
        "\n",
        "print(\"Average time\", t/5)\n",
        "\n",
        "print(\"Number of nodes explored:\", len(agent.explored))\n",
        "print(\"Number of nodes in frontier:\", len(agent.frontier))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wr2hA_YU79Mj",
        "outputId": "3bf890a2-e07f-420f-8d47-c17217dc4fc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reached goal!\n",
            "84.14444255828857\n",
            "Reached goal!\n",
            "81.00156617164612\n",
            "Reached goal!\n",
            "81.69559645652771\n",
            "Reached goal!\n",
            "80.36025023460388\n",
            "Reached goal!\n",
            "84.16625928878784\n",
            "Average time 82.27362294197083\n",
            "Number of nodes explored: 33353\n",
            "Number of nodes in frontier: 213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Best First Search**\n",
        "\n",
        "Using only Heuristic 2\n"
      ],
      "metadata": {
        "id": "dn6W0vQyct_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent2:\n",
        "\n",
        "    def __init__(self, env, heuristic):\n",
        "        self.frontier = PriorityQueue()\n",
        "        self.explored = dict()\n",
        "        self.start_state = env.get_start_state()\n",
        "        self.goal_state = env.get_goal_state()\n",
        "        self.env = env\n",
        "        self.goal_node = None\n",
        "        self.heuristic = heuristic\n",
        "\n",
        "    def run(self):\n",
        "        init_node = Node(parent = None, state = self.start_state, pcost = 0, hcost = 0)\n",
        "        self.frontier.push(init_node)\n",
        "        start = time()\n",
        "        while not self.frontier.is_empty():\n",
        "\n",
        "            curr_node = self.frontier.pop()\n",
        "            next_states = self.env.get_next_states(curr_node.state)\n",
        "\n",
        "            if hash(curr_node) in self.explored:\n",
        "                continue\n",
        "\n",
        "            self.explored[hash(curr_node)] = curr_node\n",
        "\n",
        "            if self.env.reached_goal(curr_node.state):\n",
        "                print(\"Reached goal!\")\n",
        "                self.goal_node = curr_node\n",
        "                break\n",
        "            goal_state = self.env.get_goal_state()\n",
        "\n",
        "            l = []\n",
        "            for state in next_states:\n",
        "\n",
        "                hcost = self.heuristic(state[0])\n",
        "                node = Node(parent=curr_node, state=state[0], pcost=0, hcost=hcost, action=state[1])\n",
        "                self.frontier.push(node)\n",
        "\n",
        "        end = time()\n",
        "        print(end - start)\n",
        "        return end-start\n",
        "\n",
        "    def print_nodes(self):\n",
        "\n",
        "        node = self.goal_node\n",
        "        l = []\n",
        "        while node is not None:\n",
        "            l.append(node)\n",
        "            node = node.parent\n",
        "\n",
        "        step = 1\n",
        "        for node in l[::-1]:\n",
        "            print(\"Step: \",step)\n",
        "            print(node.action)\n",
        "            #print(node)\n",
        "            step+=1\n",
        "\n",
        "t = 0\n",
        "for i in range(5):\n",
        "    agent = Agent2(Environment(), heuristic2)\n",
        "    t+=agent.run()\n",
        "\n",
        "print(\"Average time\", t/5)\n",
        "print(\"Number of nodes explored:\", len(agent.explored))\n",
        "print(\"Number of nodes in frontier:\", len(agent.frontier))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD8rzT6M7-dc",
        "outputId": "17bcc2dd-94b6-4c8c-d84b-31101f928eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reached goal!\n",
            "90.1148042678833\n",
            "Reached goal!\n",
            "89.57251024246216\n",
            "Reached goal!\n",
            "89.51896667480469\n",
            "Reached goal!\n",
            "90.58948969841003\n",
            "Reached goal!\n",
            "89.79849219322205\n",
            "Average time 89.91885261535644\n",
            "Number of nodes explored: 35997\n",
            "Number of nodes in frontier: 133\n"
          ]
        }
      ]
    }
  ]
}